{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af6b02b-467f-448d-9de8-97c6e9c67183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d34b4a1-e51c-422f-a675-f866853ea757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gokhan/hugging_face/bert_classification\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/gokhan/hugging_face/bert_classification\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af22e49-9d13-49da-a232-d2f83469529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\" #or roberta-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcad514-c96a-4a94-aa2f-858476d105e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "GRAD_ACCUMULATION = 2 # 16 x 2 = 32 (Effective batch size as perceived by the model)\n",
    "OUTPUT_DIR = \"banking77_final_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c136302-ac46-4e8e-83e3-26986cc98bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files={\n",
    "        \"train\": \"final_train_dataset/banking77_train_final.csv\", #after augmented\n",
    "        \"test\": \"final_train_dataset/banking77_test_final.csv\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "547c7194-fc68-456b-bb3d-4bf5761e5b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'Refund_not_showing_up': 0, 'activate_my_card': 1, 'age_limit': 2, 'apple_pay_or_google_pay': 3, 'atm_support': 4}\n",
      "id2label: {0: 'Refund_not_showing_up', 1: 'activate_my_card', 2: 'age_limit', 3: 'apple_pay_or_google_pay', 4: 'atm_support'}\n"
     ]
    }
   ],
   "source": [
    "labels_list = dataset['train'].unique(\"category\")\n",
    "labels_list.sort()\n",
    "num_labels = len(labels_list)\n",
    "label2id = {label: i for i, label in enumerate(labels_list)}\n",
    "id2label = {i: label for i, label in enumerate(labels_list)}\n",
    "print(f\"label2id: {dict(list(label2id.items())[:5])}\")\n",
    "print(f\"id2label: {dict(list(id2label.items())[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a297f3e-ee00-4e9d-8f37-981e2b1dbd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(batch):\n",
    "    batch['labels'] = [label2id[c] for c in batch['category']]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1abfdb-f09a-4307-ba30-c3c98081de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(encode_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f503d30-35e6-4b14-b978-22ad7b695427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(batch):\n",
    "    return tokenizer(batch['text'],truncation=True, padding='max_length', max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75946517-7b64-47e9-b17b-c68659651a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenization, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5affdcf9-f7b3-4dbd-8701-1fba2d66b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\",\"category\",])\n",
    "tokenized_datasets.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b4957a-9e44-4de3-8a16-ffc6cc08db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels = num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd975b3f-22ae-4dc6-afb6-d4dbb591f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d29e81-3e33-4e44-8cdf-8921e368b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits,labels = eval_preds\n",
    "    predictions = np.argmax(logits,axis = 1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a5b734-0d83-454b-a589-a65521d8d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy= \"epoch\",\n",
    "    save_strategy='epoch',\n",
    "    learning_rate= 2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE, # 16\n",
    "    gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4003756e-1d6a-47f1-8afc-d27e33e60341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4927/2715921758.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f80e3c-b213-4c6f-9a71-04a15f3f60ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4350' max='4350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4350/4350 12:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.143700</td>\n",
       "      <td>2.596092</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>1.300686</td>\n",
       "      <td>0.814186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>0.716656</td>\n",
       "      <td>0.883117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.459500</td>\n",
       "      <td>0.486287</td>\n",
       "      <td>0.892108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.405380</td>\n",
       "      <td>0.898102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.377806</td>\n",
       "      <td>0.903097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.351828</td>\n",
       "      <td>0.908092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.355153</td>\n",
       "      <td>0.912088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.357103</td>\n",
       "      <td>0.911089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.356783</td>\n",
       "      <td>0.913087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.353524</td>\n",
       "      <td>0.915085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.360798</td>\n",
       "      <td>0.913087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.371806</td>\n",
       "      <td>0.916084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.368842</td>\n",
       "      <td>0.916084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.371084</td>\n",
       "      <td>0.914086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4350, training_loss=0.5522301031529219, metrics={'train_runtime': 730.4129, 'train_samples_per_second': 190.166, 'train_steps_per_second': 5.956, 'total_flos': 4606082910489600.0, 'train_loss': 0.5522301031529219, 'epoch': 15.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "616f8b99-533a-4350-a3d5-4962d5c26b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cb1ce25-0fd8-4493-813b-2a523de46cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.37180572748184204,\n",
       " 'eval_accuracy': 0.916083916083916,\n",
       " 'eval_runtime': 1.6405,\n",
       " 'eval_samples_per_second': 610.183,\n",
       " 'eval_steps_per_second': 19.506,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee81e0-7a41-462c-a44c-c3afee4c0deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
